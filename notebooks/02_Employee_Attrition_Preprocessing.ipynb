{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing the Libraries"
      ],
      "metadata": {
        "id": "BEmHD8zPxrcY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JCsTVcmexiHD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading the Dataset"
      ],
      "metadata": {
        "id": "mSjXfC7rx4Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/WA_Fn-UseC_-HR-Employee-Attrition.csv\")"
      ],
      "metadata": {
        "id": "D97I--vtxwK3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing"
      ],
      "metadata": {
        "id": "6RGZKQe1x-8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropping Useless Columns"
      ],
      "metadata": {
        "id": "_UD81OdZyA2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"EmployeeCount\", \"EmployeeNumber\", \"Over18\", \"StandardHours\"], inplace=True)"
      ],
      "metadata": {
        "id": "w513maGkx5uQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These columns are constant or identifiers and do not contribute to prediction."
      ],
      "metadata": {
        "id": "I5HW2jBDyPFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding Target Variable"
      ],
      "metadata": {
        "id": "_lajg3tDySsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Attrition\"] = df[\"Attrition\"].map({\"Yes\": 1, \"No\": 0})"
      ],
      "metadata": {
        "id": "DNy98wrgyLiC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separating Features & Target"
      ],
      "metadata": {
        "id": "L7j7jOLRybXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(\"Attrition\", axis=1)\n",
        "y = df[\"Attrition\"]"
      ],
      "metadata": {
        "id": "G4yIIlQLyeaA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Categorical Variables (IMPORTANT)"
      ],
      "metadata": {
        "id": "z4kf4qXZyqXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "Ohmh1sm1ymX-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why `drop_first=True`?\n",
        "\n",
        "> Prevents multicollinearity (dummy variable trap).\n",
        "\n"
      ],
      "metadata": {
        "id": "v60LCsZpyv0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Test Split"
      ],
      "metadata": {
        "id": "4kgMF5lYy41a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "LRCoOVqzys8U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratification preserves attrition ratio in both sets."
      ],
      "metadata": {
        "id": "d0kuth88y9Sa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "8hZ-awS4zAY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "IQP3-LbNy7II"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   `fit` only on training data\n",
        "*   `transform` on test + future inputs (website)"
      ],
      "metadata": {
        "id": "YjubYiwDzERW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Saving the Artifacts"
      ],
      "metadata": {
        "id": "gXl43E_UzRSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "with open(\"feature_columns.pkl\", \"wb\") as f:\n",
        "    pickle.dump(X.columns, f)"
      ],
      "metadata": {
        "id": "PUkijPZRzDCY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Summary**\n",
        "\n",
        "* Preprocessing Summary\n",
        "\n",
        "* Removed non-informative columns\n",
        "\n",
        "* Encoded categorical features using one-hot encoding\n",
        "\n",
        "* Scaled numerical features\n",
        "\n",
        "* Created reproducible train-test split\n",
        "\n",
        "* Saved preprocessing artifacts for deployment"
      ],
      "metadata": {
        "id": "ffSbFClizX-x"
      }
    }
  ]
}